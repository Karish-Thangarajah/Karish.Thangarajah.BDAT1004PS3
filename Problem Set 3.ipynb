{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "\n",
    "Housing\n",
    "\n",
    "Step 1. Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Create 3 differents Series, each of length 100, as follows:\n",
    "\n",
    "    The first a random number from 1 to 4\n",
    "    The second a random number from 1 to 3\n",
    "    The third a random number from 10,000 to 30,000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(100):\n",
    "    list1.append(random.randint(1,4) + random.random())\n",
    "    \n",
    "series1 = pd.Series(list1)\n",
    "\n",
    "list2 = []\n",
    "for i in range(100):\n",
    "    list2.append(random.randint(1,3) + random.random())\n",
    "    \n",
    "series2 = pd.Series(list2)\n",
    "\n",
    "list3 = []\n",
    "for i in range(100):\n",
    "    list3.append(random.randint(10000,30000) + random.random())\n",
    "    \n",
    "series3 = pd.Series(list3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Create a DataFrame by joinning the Series by column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       first    second         third\n",
      "0   2.133133  3.121426  16609.637896\n",
      "1   4.541347  2.802105  18968.484581\n",
      "2   1.694262  3.977305  29161.439104\n",
      "3   2.615195  3.975069  12928.165762\n",
      "4   2.726466  3.121876  26039.033501\n",
      "..       ...       ...           ...\n",
      "95  2.276186  1.558600  18006.980733\n",
      "96  1.467994  1.882911  27973.985250\n",
      "97  1.117710  3.022457  10033.026559\n",
      "98  1.665619  3.448573  15504.822900\n",
      "99  3.013794  3.026181  28435.363229\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dFrame1 = pd.DataFrame({'first':series1, 'second':series2, 'third':series3})\n",
    "print(dFrame1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Change the name of the columns to bedrs, bathrs, price_sqr_meter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bedrs    bathrs  price_sqr_meter\n",
      "0   2.133133  3.121426     16609.637896\n",
      "1   4.541347  2.802105     18968.484581\n",
      "2   1.694262  3.977305     29161.439104\n",
      "3   2.615195  3.975069     12928.165762\n",
      "4   2.726466  3.121876     26039.033501\n",
      "..       ...       ...              ...\n",
      "95  2.276186  1.558600     18006.980733\n",
      "96  1.467994  1.882911     27973.985250\n",
      "97  1.117710  3.022457     10033.026559\n",
      "98  1.665619  3.448573     15504.822900\n",
      "99  3.013794  3.026181     28435.363229\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dFrame2 = pd.DataFrame({'bedrs':series1, 'bathrs':series2, 'price_sqr_meter':series3})\n",
    "print(dFrame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Create a one column DataFrame with the values of the 3 Series and assign it\n",
    "to 'bigcolumn'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bigcolumn\n",
      "0       2.133133\n",
      "1       4.541347\n",
      "2       1.694262\n",
      "3       2.615195\n",
      "4       2.726466\n",
      "..           ...\n",
      "95  18006.980733\n",
      "96  27973.985250\n",
      "97  10033.026559\n",
      "98  15504.822900\n",
      "99  28435.363229\n",
      "\n",
      "[300 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dFrame3 = pd.DataFrame({'bigcolumn': pd.concat([series1, series2, series3])})\n",
    "print(dFrame3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Ops it seems it is going only until index 99. Is it true?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(dFrame3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly as seen above that is not true. the individual data Series remember their indices from before the concatenation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 7. Reindex the DataFrame so it goes from 0 to 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        bigcolumn\n",
      "0        2.133133\n",
      "1        4.541347\n",
      "2        1.694262\n",
      "3        2.615195\n",
      "4        2.726466\n",
      "..            ...\n",
      "295  18006.980733\n",
      "296  27973.985250\n",
      "297  10033.026559\n",
      "298  15504.822900\n",
      "299  28435.363229\n",
      "\n",
      "[300 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dFrame3_true =  pd.DataFrame({'bigcolumn': pd.concat([series1, series2, series3], ignore_index = True)})\n",
    "print(dFrame3_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "\n",
    "Wind Statistics\n",
    "\n",
    "The data have been modified to contain some missing values, identified by NaN. Using pandas should make this exercise easier, in particular for the bonus question. You should be able to perform all of these operations without using a for loop or other looping construct.\n",
    "\n",
    "The data in 'wind.data' has the following format:\n",
    "\n",
    "Yr Mo Dy RPT VAL ROS KIL SHA BIR DUB CLA MUL CLO BEL MAL\n",
    "\n",
    "61 1 1 15.04 14.96 13.17 9.29 NaN 9.87 13.67 10.25 10.83 12.58 18.50 15.04\n",
    "\n",
    "61 1 2 14.71 NaN 10.83 6.50 12.62 7.67 11.50 10.04 9.79 9.67 17.54 13.83\n",
    "\n",
    "61 1 3 18.50 16.88 12.33 10.13 11.17 6.17 11.25 NaN 8.50 7.67 12.75 12.71\n",
    "\n",
    "The first three columns are year, month, and day. The remaining 12 columns are average windspeeds in knots at 12 locations in Ireland on that day.\n",
    "\n",
    "Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Import the dataset from this address https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Yr  Mo  Dy    RPT    VAL    ROS    KIL    SHA    BIR    DUB    CLA  \\\n",
      "0     61   1   1  15.04  14.96  13.17   9.29    NaN   9.87  13.67  10.25   \n",
      "1     61   1   2  14.71    NaN  10.83   6.50  12.62   7.67  11.50  10.04   \n",
      "2     61   1   3  18.50  16.88  12.33  10.13  11.17   6.17  11.25    NaN   \n",
      "3     61   1   4  10.58   6.63  11.75   4.58   4.54   2.88   8.63   1.79   \n",
      "4     61   1   5  13.33  13.25  11.42   6.17  10.71   8.21  11.92   6.54   \n",
      "...   ..  ..  ..    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "6569  78  12  27  17.58  16.96  17.62   8.08  13.21  11.67  14.46  15.59   \n",
      "6570  78  12  28  13.21   5.46  13.46   5.00   8.12   9.42  14.33  16.25   \n",
      "6571  78  12  29  14.00  10.29  14.42   8.71   9.71  10.54  19.17  12.46   \n",
      "6572  78  12  30  18.50  14.04  21.29   9.13  12.75   9.71  18.08  12.87   \n",
      "6573  78  12  31  20.33  17.41  27.29   9.59  12.08  10.13  19.25  11.63   \n",
      "\n",
      "        MUL    CLO    BEL    MAL  \n",
      "0     10.83  12.58  18.50  15.04  \n",
      "1      9.79   9.67  17.54  13.83  \n",
      "2      8.50   7.67  12.75  12.71  \n",
      "3      5.83   5.88   5.46  10.88  \n",
      "4     10.92  10.34  12.92  11.83  \n",
      "...     ...    ...    ...    ...  \n",
      "6569  14.04  14.00  17.21  40.08  \n",
      "6570  15.25  18.05  21.79  41.46  \n",
      "6571  14.50  16.42  18.88  29.58  \n",
      "6572  12.46  12.12  14.67  28.79  \n",
      "6573  11.58  11.38  12.08  22.08  \n",
      "\n",
      "[6574 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "WindStats = pd.read_csv(\"https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data\", delim_whitespace=True)\n",
    "print(WindStats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Assign it to a variable called data and replace the first 3 columns by a proper datetime index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "to assemble mappings requires at least that [year, month, day] be specified: [day,month,year] is missing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a8afb642753a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mWindStats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWindStats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Mo'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Yr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_assemble_from_unit_mappings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_assemble_from_unit_mappings\u001b[1;34m(arg, errors, tz)\u001b[0m\n\u001b[0;32m    829\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m         \u001b[0mrequired\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    832\u001b[0m             \u001b[1;34m\"to assemble mappings requires at least that \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;34mf\"[year, month, day] be specified: [{required}] \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: to assemble mappings requires at least that [year, month, day] be specified: [day,month,year] is missing"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 4. Year 2061? Do we really have data from this year? Create a function to fix it and apply it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 5. Set the right dates as the index. Pay attention at the data type, it should be datetime64[ns]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 6. Compute how many values are missing for each location over the entire record.They should be ignored in all calculations below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 7. Compute how many non-missing values there are in total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 8. Calculate the mean windspeeds of the windspeeds over all the locations and all the times. A single number for the entire dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 9. Create a DataFrame called loc_stats and calculate the min, max and mean windspeeds and standard deviations of the windspeeds at each location over all the days A different set of numbers for each location. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10. Create a DataFrame called day_stats and calculate the min, max and mean windspeed and standard deviations of the windspeeds across all the locations at each day. A different set of numbers for each day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 11. Find the average windspeed in January for each location. Treat January 1961 and January 1962 both as January.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 12. Downsample the record to a yearly frequency for each location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 13. Downsample the record to a monthly frequency for each location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-9e18f0f36774>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-9e18f0f36774>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Step 14. Downsample the record to a weekly frequency for each location.\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Step 14. Downsample the record to a weekly frequency for each location.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 15. Calculate the min, max and mean windspeeds and standard deviations of the windspeeds across all locations for each week (assume that the first week starts on January 2 1961) for the first 52 weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Import the dataset from this address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipotle = pd.read_csv(\"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 3. Assign it to a variable called chipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipo = chipotle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 4. See the first 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipo.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 5. What is the number of observations in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 6. What is the number of columns in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chipo.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 7. Print the name of all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(column) for column in chipo.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 8. How is the dataset indexed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by order_id where all items with the same id were ordered by the same person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 9. Which was the most-ordered item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = chipo[['item_name','quantity']]\n",
    "print(filtered.groupby('item_name').sum().sort_values('quantity', ascending=False).iloc[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chicken Bowl was the most ordered item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 10. For the most-ordered item, how many items were ordered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above 761 Chicken Bowls were ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 11. What was the most ordered item in the choice_description column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered = chipo[['choice_description','quantity']]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Step 12. How many items were orderd in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 13.\n",
    "\n",
    "    Turn the item price into a float\n",
    "    Check the item price type\n",
    "    Create a lambda function and change the type of item price\n",
    "    Check the item price type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 14. How much was the revenue for the period in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 15. How many orders were made in the period?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 16. What is the average revenue amount per order?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 17. How many different items are sold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Create a line plot showing the number of marriages and divorces per capita in the U.S. between 1867 and 2014. Label both lines and show the legend.\n",
    "\n",
    "Don't forget to label your axes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "marr_and_divor = pd.read_csv('us-marriages-divorces-1867-2014.csv')\n",
    "\n",
    "columns = marr_and_divor.columns.drop(['Year','Population','Marriages','Divorces'])\n",
    "x_data = marr_and_divor['Year']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for column in columns:\n",
    "    ax.plot(x_data, marr_and_divor[column])\n",
    "\n",
    "ax.set_title('marriages and divorces per capita in the U.S. between 1867 and 2014')\n",
    "ax.legend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Create a vertical bar chart comparing the number of marriages and divorces per capita in the U.S. between 1900, 1950, and 2000. \n",
    "\n",
    "Don't forget to label your axes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Create a horizontal bar chart that compares the deadliest actors in Hollywood. Sort the actors by their kill count and label each bar with the corresponding actor's name.\n",
    "\n",
    "Don't forget to label your axes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actorKills = pd.read_csv('actor_kill_counts.csv')\n",
    "\n",
    "actorKills.plot.barh(x='Actor',y='Count')\n",
    "print(actorKills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Create a pie chart showing the fraction of all Roman Emperors that were assassinated.\n",
    "\n",
    "Make sure that the pie chart is an even circle, labels the categories, and shows the percentage breakdown of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reignsData = pd.read_csv(\"roman-emperor-reigns.csv\")\n",
    "print(reignsData.groupby('Cause_of_Death').count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Create a scatter plot showing the relationship between the total revenue earned by arcades and the number of Computer Science PhDs awarded in the U.S. between 2000 and 2009.\n",
    "\n",
    "Don't forget to label your axes!\n",
    "\n",
    "Color each dot according to its year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "arc_vs_cs = pd.read_csv('arcade-revenue-vs-cs-doctorates.csv',names=['Year', 'Total Arcade Revenue (billions)', 'Computer Science Doctorates Awarded (US)'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(arc_vs_cs['Total Arcade Revenue (billions)'], arc_vs_cs['Computer Science Doctorates Awarded (US)'], c=arc_vs_cs['Year']-2000)\n",
    "\n",
    "ax.set_title('Arcade versus CS Doctorates Dataset')\n",
    "ax.set_xlabel('Total Arcade Revenue (billions)')\n",
    "ax.set_ylabel('Computer Science Doctorates Awarded (US)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
